{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWnS_oErBefO"
   },
   "source": [
    "# An Analysis of The Global Light Pollution Standards\n",
    "\n",
    "**Prannaya Gupta (M21404)**\n",
    "\n",
    "_Done as part of **CS4232**: Data Analytics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0Xc0V3xIbew"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jshl--ZIcaC"
   },
   "source": [
    "## Introduction\n",
    "A side-effect of technological advancement has been the amount of light pollution in the world today. Ever since Thomas Edison’s revolutionary invention of the light bulb, the world has been thrust into a landscape of light-afflicted skies. According to various studies, around 80% of people live under light pollution-afflicted skies every day, and whilst this may not affect the day-to-day life of an individual, astronomers are very much affected by the sudden illumination in the skies. Even the Singaporean sky is very much damaged by light pollution, with 99.5% of all stars being completely invisible without optical aid<sup>[22]</sup>.\n",
    "\n",
    "In this project, I aim to analyze the implications of the changes in Light Pollution levels over the past few years, utilising global and local data to find possibly relationships. As shown below, I aim to solve a list of Light Pollution-related questions that utilise alternative data to analyse and interpret patterns, including simple statistical and machine-learning related models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkVc_d5ZvKSg"
   },
   "source": [
    "## Research Questions\n",
    "\n",
    "### A.\tWhat are locations of minimal light pollution intensity which are optimum for astronomical observation?\n",
    "\n",
    "While one might think that the best locations are in the middle of wilderness or large water bodies (i.e. the ocean), these locations need to be filtered based on accessibility, especially since locations like the middle of the ocean are not feasible locations for people to assemble to watch and will thus not be a great location for astrophotography.\n",
    "\n",
    "In order to map this, I can use the absolute night-time light datasets<sup>[4-7]</sup> to analyse locations of minimal light intensity. In order to do the filtering of data, I can use the Base Map<sup>[8]</sup> and Matplotlib’s BaseMap Library<sup>[26]</sup>. This can give us a few optimum points best for this type of analysis.\n",
    "\n",
    "\n",
    "### B.\tHow has the light pollution data around the world changed? Which countries are most susceptible to high light pollution in the future? Which countries are lessening in terms of light pollution?\n",
    "\n",
    "There are many countries that have had rampant increases in Light Pollution over the past few years, while others have made an effort to reduce their already increased Light Pollution. We need to map the data in order to find out which countries are susceptible to the level of problematic light pollution that can be found in cities like Singapore.\n",
    "\n",
    "Due to the possession of the Time Series Data of night-time light pollution data<sup>[1-3]</sup>, we can easily map locations based on relative changes in absolute light magnitude. I intend to use the geolocation datasets<sup>[9-12]</sup> against the time-series night-time light datasets<sup>[1,17]</sup> to find changes and from there and map it using a possible regression model so as to predict the curve of increase/decrease. This can be used to make predictions and compare to other light pollution levels.\n",
    "\n",
    "\n",
    "### C. What are the impacts of Light Pollution on the Biodiversity around the area?\n",
    "\n",
    "High Light Pollution can have a detrimental impact on animals’ survival, hence they are likely to be found in areas with lesser light pollution, which can be adopted as a hypothesis. Another investigation could be what types of animals can be found closer to Light pollution related areas. For example, Moths should ideally be found in high light pollution, but endangered species will likely not be found in similar areas.\n",
    "\n",
    "Based on the eBird Observation Dataset<sup>[13]</sup>, we can find relative values symbolising the animals’ survival patterns and frequency of observations, thereby relating it to Time Series Night-time Light Data so as to procure information regarding how the birds have moved about in the presence of light pollution. The International Barcode of Life dataset<sup>[14]</sup> is also a logical dataset to not only map frequency patterns but also classify the observations based on existing models and thus finding frequencies of these animals based on Time Series Light Pollution.\n",
    "\n",
    "\n",
    "### D.\tWhat are the effects and relevance of different types of light facilities on light pollution in the area?\n",
    "\n",
    "One of the factors claimed culpable for the increased light pollution in Singapore is the extreme number of street lights and traffic lights. Hence, I wish to investigate how the frequency of these lights affect the light pollution around the area. I also want to find possible weights to see how relevant these frequencies are.\n",
    "\n",
    "With the presence of the Light Facilities Datasets<sup>[15-19]</sup>, we can map this on the Absolute Positional Brightness Dataset<sup>[4-7]</sup> so that we can investigate how it’s affects the actual brightness, whilst we can also investigate how it changes with respect to time by using the Time Series night-light data<sup>[1-3]</sup> and the time based datasets<sup>[15,19]</sup>. This can then be used to compute possible patterns and predictions regarding where the Singapore light pollution may lead up to. To consider Singapore alone, I will be using Geopy<sup>[25]</sup> for the most part and filtering coordinates based on available geographical information.\n",
    "\n",
    "\n",
    "### E.\tWhat is the relation between the average energy consumption and general demographics in each area (eg Tampines, Jurong etc) and the Light Pollution?\n",
    "\n",
    "A reason for considering this is the lack of mathematical analysis as to how energy consumption in specific districts affect the light pollution there. General mathematics regarding data in Singapore itself hasn’t been explored, hence using this is a good way of exploring something new. We can model the types of houses, general types of people living there, and the energy consumption based on that and from there, we can test how it affects nearby light pollution.\n",
    "\n",
    "I intend to use the Economical Datasets that give data regarding the Singapore Energy Consumption statistics<sup>[20]</sup> and the Singapore Resident demographics<sup>[21]</sup>. The usage of the Absolute positional brightness datasets<sup>[4-7]</sup>, filtering Singapore similarly to the previous research question. This can therefore be using in conjunction to find possible patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKmkinnvw9Cs"
   },
   "source": [
    "## Set-Up and Imports\n",
    "\n",
    "Firstly, we need to perform a simple set-up. This involves the following steps:\n",
    "\n",
    "1. Import the `autoreload` extension which can allow us to avoid leaving Jupyter at a stagnant file state.\n",
    "2. Install some libraries, like `np`, `imagecodecs`, `lxml` and `gdal`\n",
    "     - **Note**: For gdal, which is the Python API Wrapper for the C library GDAL, the installation is a lot more complex than just pip install, hence there is a script. Additional info is provided in the corresponding section\n",
    "3. Import libraries, which include:\n",
    "     - Crucial Ones like `random`, `re` and `glob`\n",
    "     - Mathematica Libraries like `numpy` and `scipy`\n",
    "     - Data Wrangling Libraries like `pandas` and `lxml`\n",
    "     - Plotting Libraries like `matplotlib`, `seaborn` and `plotly`\n",
    "     - Web Scraping Libraries like `bs4` and `requests`\n",
    "     - Image Processing Libraries like `cv2`, `skimage` and `PIL`\n",
    "     - Machine Learning Libraries like `sklearn`\n",
    "     \n",
    "### Installation Instructions\n",
    "\n",
    "In this project, I am using the following external libraries:\n",
    "- `scikit-image`: download using conda if possible.\n",
    "- `pillow`: predownloaded in conda, install using pip if you are using a default python environment\n",
    "- `opencv-python`: install using pip in any case\n",
    "- `lxml`: install using pip if possible\n",
    "- `geopy`: install using pip or conda\n",
    "- `geopandas`: install using conda if possible\n",
    "     - `gdal`: installed with Geopandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7ICrTmrOBdou"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# to ensure kernel resets when files change around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cK8vABqxJLmc"
   },
   "outputs": [],
   "source": [
    "import random, time, math, datetime, os, re\n",
    "from glob import glob\n",
    "import sys, tarfile, gzip\n",
    "from pprint import pprint\n",
    "\n",
    "from IPython.display import clear_output, HTML, Markdown\n",
    "from IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import np, numpy\n",
    "import pandas as pd\n",
    "from lxml import objectify, etree, html\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import stats, special\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (16.0, 8.0)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, bs4\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from skimage import filters\n",
    "from skimage.transform import rescale, resize, downscale_local_mean, swirl\n",
    "from skimage.filters import threshold_otsu, threshold_local, try_all_threshold\n",
    "import skimage.io as skio\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "import plotly.express as px\n",
    "\n",
    "import geopy, geopandas as gp\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "This section pertains to tools created with the express purpose of mathematical and image-based analyses.\n",
    "\n",
    "Here, you can find the following:\n",
    "1. Correlation Computational Methods\n",
    "2. Pandas-based customized data reading functions\n",
    "3. An Image Class for any Image Processing Concerns\n",
    "4. A GeoTiff Class to access GeoTiff files and embed it as both a GeoDataFrame and Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3ERGXfGLJQWn"
   },
   "outputs": [],
   "source": [
    "# Functions I painstakingly researched and coded with 2 shots of coffee at 3 am\n",
    "\n",
    "def gamma(n):\n",
    "    \"\"\"\n",
    "    A Simplified Gamma Function for \"powers\" of 1/2\n",
    "    Gamma Function for Integers are given by: Γ(n) = (n-1)!\n",
    "    Gamma Function for Values ending with 1/2: Γ(n) = 0.5 * 1.5 * ... * (n-1) * √(π)\n",
    "\n",
    "    Gamma Function is generally given by the following expression\n",
    "    \"\"\"\n",
    "    return np.arange(1 - (n%1), n).prod() * np.pi ** (n%1)\n",
    "\n",
    "def beta(x, y):\n",
    "    \"\"\"\n",
    "    Actual Beta Function based ont he Simplified Gamma Function above.\n",
    "    \"\"\"\n",
    "    return gamma(x)*gamma(y)/gamma(x+y)\n",
    "\n",
    "def I(x, a, b):\n",
    "    if gamma(a) == np.inf or gamma(b) == np.inf or gamma(a+b) == 0: return 0\n",
    "    if x == 0 or x == 1: return x\n",
    "    if b == 1: return x ** a\n",
    "    if a == 1: return 1 - (1-x)**b\n",
    "    if b > 1: return I(x, a, b-1) + (x**a * (1-x)**(b-1))/((b-1)*beta(a, b-1))\n",
    "    if a > 1: return I(x, a-1, b) - (x**(a-1) * (1-x)**b)/((a-1)*beta(a-1, b))\n",
    "    return ((-1)**a) * I(x/(x-1), a, 1-a-b) * beta(a, 1-a-b)\n",
    "\n",
    "\n",
    "def corr(data):\n",
    "    norm = data - data.mean(axis=0)\n",
    "    return norm.prod(axis=1).sum() / np.sqrt((norm**2).sum(axis=0).prod())\n",
    "\n",
    "def p(r, bound):\n",
    "    return 2*I((1-abs(r))/2, bound, bound)\n",
    "\n",
    "def pearson(data):\n",
    "    r = corr(data)\n",
    "    return r, p(r, data.shape[0]/2-1)\n",
    "\n",
    "def pearsonr(x, y):\n",
    "    x, y = x - x.mean(axis=0), y - y.mean(axis=0)\n",
    "    r = (x.T @ y).sum(axis=0) / np.sqrt(((x**2).sum(axis=0) * (y**2).sum(axis=0)))\n",
    "    p_val = 2 * np.vectorize(lambda r: p(r, x.shape[0]/2-1))(r)\n",
    "    return np.stack((r, p_val), axis=len(r.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(loc, *args, **kwargs):\n",
    "    if re.search(r\"[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", loc):\n",
    "        return read_csv(requests.get(loc, allow_redirects=True).content, *args, **kwargs)\n",
    "    loc = loc.strip(\"\\n\")\n",
    "    if re.search(r\"[\\n:<>\\\"/\\|?*]\", loc):\n",
    "        return pd.read_csv(StringIO(loc), *args, **kwargs)\n",
    "    else:\n",
    "        return pd.read_csv(loc, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kwFCtUkfJWJu"
   },
   "outputs": [],
   "source": [
    "class Resize:\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "\n",
    "    def __call__(self, func):\n",
    "        return self.img.apply(lambda img: resize(img, func(img.shape)), \"Resized Version of \"+self.img.name)\n",
    "\n",
    "    # def local_mean(self, output_shape):\n",
    "    #     return self.img.apply(lambda img: resize_local_mean(img, output_shape), self.img.name+\" resized by local mean \"+str(output_shape))\n",
    "\n",
    "\n",
    "class Plot:\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "\n",
    "    def __call__(self):\n",
    "        self.img.show()\n",
    "\n",
    "    def contour(self, ax=None, title=\"\"):\n",
    "        self.img.contourplot(ax=ax, title=title)\n",
    "\n",
    "    def imageReport(self):\n",
    "        self.img.createImageReport()\n",
    "\n",
    "class LatLong:\n",
    "    def __init__(self, img):\n",
    "        self.h, self.w = img.h, img.w\n",
    "\n",
    "    def LongfromX(self, x):\n",
    "        return 360 * x / self.w - 180\n",
    "\n",
    "    def LatfromY(self, y):\n",
    "        return - np.arctan(np.sinh((y / self.h) * 2 * np.pi - np.pi)) * 180 / np.pi\n",
    "\n",
    "    def XfromLong(self, long):\n",
    "        return (x + 180) * self.w / 360\n",
    "\n",
    "    def YfromLat(self, lat):\n",
    "        y = (np.arcsinh(np.tan(lat * np.pi / 180)) + np.pi) * self.h / (2 * np.pi)\n",
    "\n",
    "class Image:\n",
    "    def __init__(self, img: np.ndarray, name: str, path: str = \"\"):\n",
    "        if name == \"\":\n",
    "            name = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        self.name = name\n",
    "        self.title = \"Image of \" + name\n",
    "        self.path = path\n",
    "        self.img = img\n",
    "        self.isGray = len(self.img.shape) == 2\n",
    "        self.resize = Resize(self)\n",
    "        self.plot = Plot(self)\n",
    "        self.latlong = LatLong(self)\n",
    "\n",
    "    @classmethod\n",
    "    def open(cls, path: str, name: str = \"\"):\n",
    "        return cls(skio.imread(path), name=name, path=path)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path:str, name:str = \"\"):\n",
    "        if re.search(r\"[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", path) and re.search(\"((http|https)://)(www.)?[a-zA-Z0-9@:%._\\\\+~#?&//=]{2,256}\\\\.[a-z]{2,6}\\\\b([-a-zA-Z0-9@:%._\\\\+~#?&//=]*)\", path):\n",
    "            return cls(np.asarray(PIL.Image.read(requests.get(url, stream=True).raw)), name=name, path=path)\n",
    "        else: return cls(skio.imread(path), name=name, path=path)\n",
    "\n",
    "    def show(self, title=\"\", ax=None):\n",
    "        if ax is None:\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(self.img, cmap=\"gray\" if self.isGray else None)\n",
    "            plt.title(title if title else self.title)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.axis(\"off\")\n",
    "            ax.imshow(self.img, cmap=\"gray\" if self.isGray else None)\n",
    "            ax.set_title(title if title else self.title)\n",
    "\n",
    "        return \"%s - Retrieved from %s with Shape %s\" % (self.title, self.path, self.shape)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.show()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def to_numpy(self):\n",
    "        return self.img\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.img.shape\n",
    "\n",
    "    @property\n",
    "    def h(self):\n",
    "        return self.img.shape[0]\n",
    "\n",
    "    @property\n",
    "    def w(self):\n",
    "        return self.img.shape[1]\n",
    "\n",
    "    def gray(self):\n",
    "        return self if self.isGray else Image(rgb2gray(self.img), name=\"Grayscale of \"+self.name, path=self.path)\n",
    "\n",
    "    def red(self):\n",
    "        img = self.img.copy()\n",
    "        img[:, :, 1:] = 0\n",
    "        return Image(img, name=\"Red Part of \"+self.name, path=self.path)\n",
    "\n",
    "    def green(self):\n",
    "        img = self.img.copy()\n",
    "        img[:, :, ::2] = 0\n",
    "        return Image(img, name=\"Green Part of \"+self.name, path=self.path)\n",
    "\n",
    "    def blue(self):\n",
    "        img = self.img.copy()\n",
    "        img[:, :, :2] = 0\n",
    "        return Image(img, name=\"Blue Part of \"+self.name, path=self.path)\n",
    "\n",
    "    def flipud(self):\n",
    "        return Image(np.flipud(self.img), name=self.name+\" Flipped Vertically\", path=self.path)\n",
    "\n",
    "    def fliplr(self):\n",
    "        return Image(np.fliplr(self.img), name=self.name+\" Flipped Horizontally\", path=self.path)\n",
    "\n",
    "    def invert(self):\n",
    "        return Image((1 if np.all(self.img < 1) else 63 if np.all(self.img < 64) else 255) - self.img, name=self.name+\" Inverted\", path=self.path)\n",
    "\n",
    "    def transpose(self):\n",
    "        return Image(np.transpose(self.img, [1, 0, 2]), name=self.name+\" Transposed\", path=self.path)\n",
    "\n",
    "    def spotlight(self):\n",
    "        img = np.copy(self.img)\n",
    "        h, w = img.shape\n",
    "        img[np.sqrt(np.arange(-(w-1)/2, (w+1)/2)**2 + np.arange(-(h-1) /\n",
    "                    2, (h+1)/2)[:, np.newaxis] ** 2) > min(h, w)/2] = 0\n",
    "        return Image(img, name=\"Spotlight of \"+self.name, path=self.path)\n",
    "\n",
    "    def convolve(self, kernel):\n",
    "        image = self.img\n",
    "        return Image((np.transpose(np.transpose(image[np.arange(kernel.shape[1]) + np.arange(image.shape[0] + 1 - kernel.shape[0])[:, np.newaxis]], (0, 2, 1))[:, np.arange(kernel.shape[0]) + np.arange(image.shape[1] + 1 - kernel.shape[1])[:, np.newaxis]], (0, 1, 3, 2)) * kernel).sum((2, 3)), name=self.name+\" Convolved\", path=self.path)\n",
    "\n",
    "    def blur(self, patchSize):\n",
    "        return Image(self.convolve(kernel=np.full((patchSize, patchSize), 1/patchSize**2)).to_numpy(),\n",
    "                     name=\"{}% Blur of {}\".format(patchSize, self.name), path=self.path)\n",
    "\n",
    "    def colorHist(self, title=\"\", ax=None):\n",
    "        if ax is None:\n",
    "            plt.hist(self.img.ravel(), bins=256)\n",
    "            plt.title(title if title else \"Color Histogram of %s\" % self.name)\n",
    "            plt.show()\n",
    "        else:\n",
    "            ax.hist(self.img.ravel(), bins=256)\n",
    "            ax.set_title(\n",
    "                title if title else \"Color Histogram of %s\" % self.name)\n",
    "\n",
    "    def threshColorHist(self, thresh, title=\"\", ax=None):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "        self.colorHist(\n",
    "            ax=ax, title=self.title if self.title else \"Thresholded Color Histogram of %s\" % self.name)\n",
    "        try:\n",
    "            thresh = float(thresh)\n",
    "            ax.axvline(x=thresh, color=\"r\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def laplacian(self):\n",
    "        return Image(cv2.Laplacian(self.img, cv2.CV_64F), \"Laplacian Filter on \"+self.name, path=self.path)\n",
    "\n",
    "    def sobelX(self):\n",
    "        return Image(cv2.Sobel(self.img, cv2.CV_64F, 1, 0, ksize=5), \"Sobel X Filter on \"+self.name, path=self.path)\n",
    "\n",
    "    def sobelY(self):\n",
    "        return Image(cv2.Sobel(self.img, cv2.CV_64F, 0, 1, ksize=5), \"Sobel Y Filter on \"+self.name, path=self.path)\n",
    "\n",
    "    def sobel(self):\n",
    "        return Image(filters.sobel(self.gray().img), \"Sobel Filter on \"+self.name, path=self.path)\n",
    "\n",
    "    def toColor(self):\n",
    "        return Image(cv2.cvtColor(self.img, cv2.COLOR_GRAY2RGB), \"Colorized \"+self.name, path=self.path) if self.isGray else self\n",
    "\n",
    "    def rescale(self, scale):\n",
    "        return self.apply(lambda img: rescale(img, scale), self.name + \" Rescaled to {.2f}%\".format(scale*100))\n",
    "\n",
    "    def swirl(self, rotation=0, strength=10, radius=120, *args, **kwargs):\n",
    "        return self.apply(lambda img: swirl(img, rotation=rotation, strength=strength, radius=radius, *args, **kwargs), self.name+\" Swirled\")\n",
    "\n",
    "    def contourplot(self, ax=None, title=\"\"):\n",
    "        if ax is None:\n",
    "            plt.contour(self.img, [50, 200])\n",
    "            plt.title(title if title else \"Contourplot of %s\" % self.title)\n",
    "        else:\n",
    "            ax.contour(self.img, [50, 200])\n",
    "            ax.set_title(title if title else \"Contourplot of %s\" % self.title)\n",
    "\n",
    "    def apply(self, func, name=\"\"):\n",
    "        return Image(func(self.img), name=name if len(name) else \"Function on \"+self.name, path=self.path)\n",
    "\n",
    "    def threshold(self, func, name=\"\"):\n",
    "        return Image(self.img > func(self.img), name=name if len(name) else \"Thresholding Function on \"+self.name, path=self.path)\n",
    "\n",
    "    def scattered(self):\n",
    "        edges_img = self.sobel().img\n",
    "        x, y = np.argwhere(edges_img > 0.07).T\n",
    "        return y, -x\n",
    "\n",
    "    def scatter(self, ax=None, s=0.1, title=\"\", figsize=(10, 13)):\n",
    "        x, y = img.scattered()\n",
    "        if ax is None:\n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.scatter(x, y, s=s)\n",
    "            plt.title(title if title else \"Scatterplot of %s\" % self.title)\n",
    "        else:\n",
    "            ax.scatter(x, y, s=s)\n",
    "            ax.set_title(title if title else \"Scatterplot of %s\" % self.title)\n",
    "\n",
    "        return stats.pearsonr(x, y)\n",
    "\n",
    "    def createImageReport(self):\n",
    "        img = self.toColor() if self.isGray else self\n",
    "        gray = self if self.isGray else self.gray()\n",
    "\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(30, 30))\n",
    "\n",
    "        img.show(title=\"Original \"+img.title, ax=axes[0, 0])\n",
    "        img.flipud().show(ax=axes[0, 1])\n",
    "        img.fliplr().show(ax=axes[0, 2])\n",
    "        img.transpose().show(ax=axes[0, 3])\n",
    "\n",
    "        img.red().show(ax=axes[1, 0])\n",
    "        img.blue().show(ax=axes[1, 1])\n",
    "        img.green().show(ax=axes[1, 2])\n",
    "        img.invert().show(ax=axes[1, 3])\n",
    "\n",
    "        img.laplacian().show(ax=axes[2, 0])\n",
    "        img.sobelX().show(ax=axes[2, 1])\n",
    "        img.sobelY().show(ax=axes[2, 2])\n",
    "        img.sobel().show(ax=axes[2, 3])\n",
    "\n",
    "        gray.threshold(\n",
    "            threshold_otsu, name=\"Global Thresholding of \"+img.name).show(ax=axes[3, 0])\n",
    "        gray.spotlight().show(ax=axes[3, 1])\n",
    "        gray.blur(15).show(ax=axes[3, 2])\n",
    "        gray.colorHist(ax=axes[3, 3])\n",
    "\n",
    "\n",
    "class GeoTiff(gp.GeoDataFrame):\n",
    "    def __init__(self, ds, name):\n",
    "        self.ds = ds\n",
    "        self.img = ds.GetRasterBand(1).ReadAsArray().astype(np.uint8)\n",
    "        self.cols = ds.RasterXSize\n",
    "        self.rows = ds.RasterYSize\n",
    "        self.shape = np[self.rows, self.cols]\n",
    "        self.geotransform = np.array(ds.GetGeoTransform())\n",
    "        self.xmin = geotransform[0]\n",
    "        self.xmax = np[1, cols] @ geotransform[:2]\n",
    "        self.xbounds = np[self.xmin, self.xmax]\n",
    "        self.ymin = np[1, rows] @ geotransform[3:6:2]\n",
    "        self.ymax = geotransform[3]\n",
    "        self.ybounds = np[self.ymin, self.ymax]\n",
    "        self.centerx = self.xbounds.mean()\n",
    "        self.centery = self.ybounds.mean()\n",
    "        self.center = np[self.centerx, self.centery]\n",
    "\n",
    "        path = ds.getDescription()\n",
    "\n",
    "        self.df = pd.DataFrame(self.img, index=np.linspace(self.ymin, self.ymax, self.rows), columns=np.linspace(self.xmin, self.xmax, self.cols)).stack().replace(0, np.nan).dropna().reset_index().rename(columns={\"level_1\":\"Longitude\", \"level_0\":\"Latitude\", 0: \"Intensity\"})\n",
    "\n",
    "        gp.GeoDataFrame.__init__(self.df, geometry=gp.points_from_xy(self.df.Longitude, self.df.Latitude))\n",
    "        #Image.__init__(self, img=img, name=name, path=path)\n",
    "\n",
    "    @classmethod\n",
    "    def open(cls, path: str, name: str = \"\"):\n",
    "        return cls(gdal.Open(path, gdal.GA_ReadOnly), name=name)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path: str, name: str = \"\"):\n",
    "        return cls(gdal.Open(path, gdal.GA_ReadOnly), name=name)\n",
    "\n",
    "    def folium(self):\n",
    "        m = folium.Map(location=self.center, zoom_start=1, tiles='Stamen Terrain')\n",
    "        incidents = folium.map.FeatureGroup()\n",
    "        pd.DataFrame.apply(self, lambda row: incidents.add_child(folium.CircleMarker([row.Latitude, row.Longitude], radius=5, color='yellow', fill=True, fill_color='blue', fill_opacity=0.6)) and folium.Marker([row.Latitude, row.Longitude], popup=f\"<span style=\\\"color:#0000FF\\\">{row.Intensity}</span>\").add_to(m), axis = 1)\n",
    "        m.add_child(incidents)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "I will be acquiring the following datasets in this project:\n",
    "1. [A harmonized global nighttime light dataset 1992–2018](https://www.nature.com/articles/s41597-020-0510-y)\n",
    "2. [Globe At Night - Sky Brightness Monitoring Network (GaN-MN)](https://www.globeatnight.org/maps.php)\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquring Harmonized Global Nighttime Light (1992 - 2018) Dataset\n",
    "This dataset is specifically the largest, containing close to 20 billion data points (specifically 20322960028), hence this data has to be acquired in chunks. All the data can be downloaded from a zip file as shown below, and I suggest running the following script on Git Bash, WSL or the Terminal. In case these are not at one's disposal, here are the instructions:\n",
    "1. Download the zip file from https://figshare.com/ndownloader/articles/9828827/versions/2\n",
    "2. Make a directory relative to this notebook called `data/nightLight`\n",
    "3. Unzip all the contents in the zip file into the `nightLight` directory as created in step 2.\n",
    "4. Remove the zip file, so as to conserve disk space.\n",
    "\n",
    "Installation can take place as follows:\n",
    "```sh\n",
    "mkdir -p data/nightLight\n",
    "curl https://figshare.com/ndownloader/articles/9828827/versions/2 > nightLight.zip\n",
    "unzip nightLight.zip -d data/nightLight/\n",
    "rm nightLight.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16801, 43201)\n",
      "X Bounds: (-180.00416666665, 180.00416522665)\n",
      "Y Bounds: (-65.00416610665, 75.00416666665)\n",
      "Center: (-7.200000027296483e-07, 5.000000279999995)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.35 GiB for an array with shape (725820001,) and data type int16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25488/2635267462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mxbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"level_1\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Longitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"level_0\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Latitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Intensity\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mgdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLatitude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\analytics\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(self, level, dropna)\u001b[0m\n\u001b[0;32m   8132\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8134\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"stack\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\analytics\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(frame, level, dropna)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\analytics\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2058\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2060\u001b[1;33m             \u001b[0mnew_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlevel_codes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlevel_codes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m             return MultiIndex(\n",
      "\u001b[1;32m~\\.conda\\envs\\analytics\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2058\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2060\u001b[1;33m             \u001b[0mnew_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlevel_codes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlevel_codes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m             return MultiIndex(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.35 GiB for an array with shape (725820001,) and data type int16"
     ]
    }
   ],
   "source": [
    "ds = gdal.Open('data/nightLight/Harmonized_DN_NTL_1992_calDMSP.tif', gdal.GA_ReadOnly)\n",
    "img = ds.GetRasterBand(1).ReadAsArray().astype(np.uint8)\n",
    "shape = np[ds.RasterYSize, ds.RasterXSize]\n",
    "print(\"Shape:\", tuple(shape))\n",
    "geotransform = np.array(ds.GetGeoTransform())\n",
    "xbounds = np[geotransform[0], np[1, shape[-1]] @ geotransform[:2]]\n",
    "print(\"X Bounds:\", tuple(xbounds))\n",
    "ybounds = np[np[1, shape[0]] @ geotransform[3:6:2], geotransform[3]]\n",
    "print(\"Y Bounds:\", tuple(ybounds))\n",
    "center = np[xbounds.mean(), ybounds.mean()]\n",
    "print(\"Center:\", tuple(center))\n",
    "index = np.linspace(*ybounds, shape[0], dtype=np.uint8)\n",
    "columns = np.linspace(*xbounds, shape[1], dtype=np.uint8)\n",
    "df = pd.DataFrame(img, index=index, columns=columns, dtype=np.uint8)\n",
    "df = df.stack().reset_index()\n",
    "df = df.rename(columns={\"level_1\":\"Longitude\", \"level_0\":\"Latitude\", 0: \"Intensity\"})\n",
    "gdf = gp.GeoDataFrame(df, geometry=gp.points_from_xy(df.Longitude, df.Latitude))\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "O88NEwlwJXDi",
    "outputId": "6f406f89-89a6-4e82-9dd2-98c91186c8a9"
   },
   "outputs": [],
   "source": [
    "#img = GeoTiff.read('data/nightLight/Harmonized_DN_NTL_1992_calDMSP.tif', \"1992 Light Pollution\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1992 = img.to_numpy()\n",
    "latlong = pd.DataFrame(data1992).rename(index=img.latlong.LatfromY, columns=img.latlong.LongfromX).stack()\n",
    "#.reset_index().rename(columns={\"level_1\":\"Longitude\", \"level_0\":\"Latitude\", 0: \"Pollution\"})\n",
    "latlong = latlong[latlong > 0].reset_index().rename(columns={\"level_1\":\"Longitude\", \"level_0\":\"Latitude\", 0: \"Pollution\"})\n",
    "latlong #.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latlong.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(projection='3d')\n",
    "X, Y = np.meshgrid(latlong.columns, latlong.index)\n",
    "ax.plot_surface(X, Y, latlong, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Longitude\", y=\"Latitude\", hue=\"Pollution\", data=latlong)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring the Globe At Night Dataset\n",
    "Globe At Night collects data based on specific locations, and in this case, contains a column named `LimitingMag` which can be related to Light Pollution standards in the region. The following commands showcase a way to download the dataset programmatically, while also removing unnecessary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zJt0WslkWJSI",
    "outputId": "d889edbd-f90f-4113-dd5d-9298a6b6609f"
   },
   "outputs": [],
   "source": [
    "gan_url = \"https://www.globeatnight.org/\"\n",
    "files = [gan_url + i[\"href\"] for i in BeautifulSoup(requests.get(gan_url+\"maps.php\").content, \"lxml\").findAll(href=re.compile(\"\\.csv$\"))]\n",
    "!mkdir -p data/gan\n",
    "gan = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    filename = \"data/gan/\"+file.split(\"/\")[-1]\n",
    "    file = BytesIO(requests.get(file, allow_redirects=True).content)\n",
    "    data = pd.read_csv(file, error_bad_lines=False)[[\"Latitude\", \"Longitude\", \"LocalDate\", \"LocalTime\", \"UTDate\", \"UTTime\", \"LimitingMag\", \"Country\"]]\n",
    "    data = data[data.LimitingMag > 0]\n",
    "    data.LocalTime = pd.to_datetime(data.apply(lambda row: row[\"LocalDate\"] + \" \" + row[\"LocalTime\"], axis=1), format='%Y-%m-%d %H:%M')\n",
    "    data.UTTime = pd.to_datetime(data.apply(lambda row: row[\"UTDate\"] + \" \" + row[\"UTTime\"], axis=1), format='%Y-%m-%d %H:%M')\n",
    "    data = data[[\"Latitude\", \"Longitude\", \"LocalTime\", \"UTTime\", \"LimitingMag\", \"Country\"]]\n",
    "    data.to_csv(filename)\n",
    "    gan.append(data)\n",
    "\n",
    "gan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan[0].Country.unique() #.groupby(\"UTTime\").LimitingMag.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring the iBOL Dataset\n",
    "iBOL is also a pretty important dataset which collects animal images and maps them to locations, hence showing possible locations of certain animals to be found. This also requires downloading the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ud7-QAPOWfc",
    "outputId": "908034d1-550a-400a-c1c0-31321933fed0"
   },
   "outputs": [],
   "source": [
    "!curl https://hosted-datasets.gbif.org/ibol/ibol.zip > ibol.zip\n",
    "!mkdir -p data/ibol/\n",
    "!unzip ibol.zip -d data/ibol/\n",
    "!rm data/ibol.zip\n",
    "\n",
    "xml_data = html.parse('data/ibol/meta.xml').getroot().getchildren()[0].getchildren()[0].getchildren()\n",
    "xml_data = xml_data[:1] + xml_data[3:]\n",
    "ibol_meta = {}\n",
    "for el in xml_data:\n",
    "    el = html.document_fromstring(etree.tostring(el))\n",
    "    ibol_meta[el.xpath(\"//files\")[0].getchildren()[0].text] = [i.get(\"term\").split(\"/\")[-1] for i in el.xpath(\"//field\")]\n",
    "\n",
    "pprint(ibol_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x560i4jnzcyG",
    "outputId": "b6891427-4b59-46b5-8354-765b255dd92c"
   },
   "outputs": [],
   "source": [
    "!cat ibol/occurrences.txt | head -n 10\n",
    "ibol_occ = pd.read_csv(\"data/ibol/occurrences.txt\", delimiter=\"\\t\", names=ibol_meta[\"occurrences.txt\"])\n",
    "ibol_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "id": "hrf_qQOczfef",
    "outputId": "c460606f-7f85-4e0c-860a-9c138b6a4313"
   },
   "outputs": [],
   "source": [
    "!cat ibol/media.txt | head -n 10\n",
    "ibol_media = pd.read_csv(\"data/ibol/media.txt\", delimiter=\"\\t\", names=ibol_meta[\"media.txt\"])\n",
    "ibol_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIIag2iozf2w",
    "outputId": "5aa0c72b-2e8f-433a-d062-3424c426f815"
   },
   "outputs": [],
   "source": [
    "!cat ibol/sequence.txt | head -n 10\n",
    "ibol_seq = pd.read_csv(\"data/ibol/sequence.txt\", delimiter=\"\\t\", names=ibol_meta[\"sequence.txt\"])\n",
    "ibol_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0l53_GkbZvu"
   },
   "outputs": [],
   "source": [
    "dmsp_ols_url = \"https://ngdc.noaa.gov\"\n",
    "dmsp_ols = requests.get(dmsp_ols_url+\"/eog/dmsp/downloadV4composites.html\").content\n",
    "files = [dmsp_ols_url + i[\"href\"].replace(\"\\n\", \"\") for i in BeautifulSoup(dmsp_ols, \"lxml\").find_all(\"table\", class_=\"list\")[0].find_all(\"a\")]\n",
    "!rm -r dmsp\n",
    "!mkdir dmsp_tar dmsp_tif dmsp\n",
    "for file in files:\n",
    "  print(file)\n",
    "  filename = \"dmsp_tar/\"+file.split(\"/\")[-1]\n",
    "  r = requests.get(file, allow_redirects=True)\n",
    "  with open(filename, 'wb') as fileobj: fileobj.write(r.content)\n",
    "\n",
    "!for f in dmsp_tar/*.tar; do tar xf \"$f\" -C dmsp_tif/; done\n",
    "!rm dmsp_tar/*.tar\n",
    "!gunzip -r dmsp_tif\n",
    "!rm dmsp/*.gz\n",
    "output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pb686giAEVA8"
   },
   "source": [
    "GBIF.org (11 September 2021) GBIF Occurrence Download  https://doi.org/10.15468/dl.vkf37t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring Lat-Long Dataset For Countries Worldwide\n",
    "This dataset is pretty explanatory, and quite possibly the easiest to acquire. I have simply read Google Developers' `countries.csv` public dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_latlong = pd.read_html(requests.get(\"https://developers.google.com/public-data/docs/canonical/countries_csv\").content)[0].set_index(\"name\")\n",
    "countries_latlong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring NASA's EaN Blue Marble 2016 Dataset\n",
    "Link: [https://visibleearth.nasa.gov/images/144898/earth-at-night-black-marble-2016-color-maps](https://visibleearth.nasa.gov/images/144898/earth-at-night-black-marble-2016-color-maps)\n",
    "\n",
    "Satellite images of Earth at night—often referred to as “night lights”—have been a curiosity for the public and a tool of fundamental research for at least 25 years. They have provided a broad, beautiful picture, showing how humans have shaped the planet and lit up the darkness. Produced every decade or so, such maps have spawned hundreds of pop-culture uses and dozens of economic, social science, and environmental research projects.\n",
    "\n",
    "These images show Earth’s night lights as observed in 2016. The data were reprocessed with new compositing techniques that select the best cloud-free nights in each month over each land mass.\n",
    "\n",
    "The images are available as JPEG and GeoTIFF, in three different resolutions: 0.1 degrees (`3600x1800`), 3km (`13500x6750`), and 500m (`86400x43200`). The 500m global map is divided into tiles (21600x21600) according to a gridding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black Marble\n",
    "blackMarble2016 = list(np.vectorize(\"https://eoimages.gsfc.nasa.gov/images/imagerecords/144000/144898/BlackMarble_2016_{}_geo.tif\".format)(np.array([\"A\", \"B\", \"C\", \"D\"], dtype=object)[:, np.newaxis] + np.array([\"1\", \"2\"], dtype=object)).flatten())\n",
    "blackMarble2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring Global Radiance Calibrated Nighttime Lights Dataset\n",
    "The Global Radiance Calibrated Nighttime Lights, hereby referred to as the RadCal dataset, contains multiple GeoTiff files saved as `.tgz`, hence the task is to first unzip this tar file and then open the GeoTiff Images. The code below contains the exact method to install this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [a[\"href\"] for a in BeautifulSoup(requests.get(\"https://ngdc.noaa.gov/eog/dmsp/download_radcal.html\").content).find_all(\"table\")[1].find_all(\"a\", href=True) if a[\"href\"].startswith(\"https\")][::2]\n",
    "pprint(urls)\n",
    "!mkdir -p data/radcal\n",
    "radcal = []\n",
    "for url in urls:\n",
    "    print(url)\n",
    "    fn = \"data/radcal/\"+url.split(\"/\")[-1]\n",
    "    with open(fn, \"wb\") as file: file.write(requests.get(url).content)\n",
    "    tar = tarfile.open(fn, \"r\")\n",
    "    for file in tar:\n",
    "        tar.extract(file, \".\".join(fn.split(\".\")[:-1])+\"/\")\n",
    "!ls data/radcal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring Geonames Datasets\n",
    "Geonames is used to get simple country demographics. While we are only really considering Singapore on a microscopic level, this is used especially to segment the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocountries = pd.read_html(requests.get(\"https://www.geonames.org/countries/\").content)[1]\n",
    "geocountries.Continent.replace(np.nan, \"NA\", inplace=True)\n",
    "geocountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geostats = pd.read_html(requests.get(\"https://www.geonames.org/statistics/\").content)[1].loc[:250]\n",
    "geostats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "ProjectPrannayaGupta.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "1c99e64c7194d82fe71825e66e1490458bc758d9d8382ab99f449926b2d76be4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
